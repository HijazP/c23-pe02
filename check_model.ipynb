{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "154cda1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/anggapark/miniconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: sastrawi in /home/anggapark/miniconda3/envs/tf/lib/python3.10/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d37334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import random\n",
    "# from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6733ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "course = pd.read_csv('course.csv')\n",
    "problem = pd.read_csv('problemstate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a23ce8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseID</th>\n",
       "      <th>judul</th>\n",
       "      <th>deskripsi</th>\n",
       "      <th>dampak</th>\n",
       "      <th>modul</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fundamental Course (1)</td>\n",
       "      <td>Fundamental Attitude toward sustainability</td>\n",
       "      <td>mengubah paradigma mengenai sustainability; Me...</td>\n",
       "      <td>Perubahan menuju sustainable mindset; 5 Prinsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fundamental Course (2)</td>\n",
       "      <td>Innovation method as problem solving</td>\n",
       "      <td>Memahami konsep Growth Mindset; Memahami konse...</td>\n",
       "      <td>Growth mindset; Design thinking; Lean Startup;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Fundamental Course (3)</td>\n",
       "      <td>The way to build sustainable business</td>\n",
       "      <td>Mengenal Sustainable Startup; Memahami SDGs po...</td>\n",
       "      <td>Mengenal Sustainable Startup; SDGs 12 Responsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Indonesia Sustainability Coral Reef University...</td>\n",
       "      <td>Terumbu karang menutupi kurang dari 1% wilayah...</td>\n",
       "      <td>pelindungan habibat; mengurangi polusi; mengur...</td>\n",
       "      <td>Sustainability Leadership; Coral Reef Ecology;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ecotourism</td>\n",
       "      <td>Seiring dengan pelonggaran perjalanan dan stab...</td>\n",
       "      <td>Pelestarian ekosistem terhadap biodiversitas; ...</td>\n",
       "      <td>Ecoturism Introduction; Sustainable Tourism Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Moringa Academy</td>\n",
       "      <td>Moringa Oliefera (kelor) merupakan salah satu ...</td>\n",
       "      <td>Mengembangkan, memelihara dan melindungi hutan...</td>\n",
       "      <td>Pengenalan Kelor; Pemahaman Kelor Melalui sosi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Indonesia Sustainable Social Forestry Educatio...</td>\n",
       "      <td>Program ini terkait dengan potensi \"perhutanan...</td>\n",
       "      <td>Pemasaran produk-produk hutan yang Berkelanjut...</td>\n",
       "      <td>Forest Management and Conservation Program (FM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Waste Management</td>\n",
       "      <td>Bukan hanya kota yang darurat sampah, Desa Des...</td>\n",
       "      <td>pelindungan habitat; mengurangi polusi sampah ...</td>\n",
       "      <td>Eco Literasi (Perubahan Mindset; 5 Prinsip Eko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Integrated Farming</td>\n",
       "      <td>Sistem pertanian terpadu merupakan sistem inte...</td>\n",
       "      <td>Menjaga keseimbangan ekosistem di dalamnya\\nse...</td>\n",
       "      <td>Analisis Masalah Sistem pertanian dan pengenal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Solar Academy</td>\n",
       "      <td>Pemerintah Indonesia saat ini memiliki target ...</td>\n",
       "      <td>Memberikan pengetahuan dan informasi\\nterkini ...</td>\n",
       "      <td>Dasar - dasar solar PV\\r\\nPemahaman dasar rang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Program Startup</td>\n",
       "      <td>Pemerintah Indonesia saat ini memiliki target ...</td>\n",
       "      <td>Munculnya usaha baru berbasis isu &amp;\\npotensi D...</td>\n",
       "      <td>Sustainable Startup (Mengenal Sustainable Star...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    courseID                                              judul   \n",
       "0          1                             Fundamental Course (1)  \\\n",
       "1          2                             Fundamental Course (2)   \n",
       "2          3                             Fundamental Course (3)   \n",
       "3          4  Indonesia Sustainability Coral Reef University...   \n",
       "4          5                                         Ecotourism   \n",
       "5          6                                    Moringa Academy   \n",
       "6          7  Indonesia Sustainable Social Forestry Educatio...   \n",
       "7          8                                   Waste Management   \n",
       "8          9                                 Integrated Farming   \n",
       "9         10                                      Solar Academy   \n",
       "10        11                                    Program Startup   \n",
       "\n",
       "                                            deskripsi   \n",
       "0          Fundamental Attitude toward sustainability  \\\n",
       "1                Innovation method as problem solving   \n",
       "2               The way to build sustainable business   \n",
       "3   Terumbu karang menutupi kurang dari 1% wilayah...   \n",
       "4   Seiring dengan pelonggaran perjalanan dan stab...   \n",
       "5   Moringa Oliefera (kelor) merupakan salah satu ...   \n",
       "6   Program ini terkait dengan potensi \"perhutanan...   \n",
       "7   Bukan hanya kota yang darurat sampah, Desa Des...   \n",
       "8   Sistem pertanian terpadu merupakan sistem inte...   \n",
       "9   Pemerintah Indonesia saat ini memiliki target ...   \n",
       "10  Pemerintah Indonesia saat ini memiliki target ...   \n",
       "\n",
       "                                               dampak   \n",
       "0   mengubah paradigma mengenai sustainability; Me...  \\\n",
       "1   Memahami konsep Growth Mindset; Memahami konse...   \n",
       "2   Mengenal Sustainable Startup; Memahami SDGs po...   \n",
       "3   pelindungan habibat; mengurangi polusi; mengur...   \n",
       "4   Pelestarian ekosistem terhadap biodiversitas; ...   \n",
       "5   Mengembangkan, memelihara dan melindungi hutan...   \n",
       "6   Pemasaran produk-produk hutan yang Berkelanjut...   \n",
       "7   pelindungan habitat; mengurangi polusi sampah ...   \n",
       "8   Menjaga keseimbangan ekosistem di dalamnya\\nse...   \n",
       "9   Memberikan pengetahuan dan informasi\\nterkini ...   \n",
       "10  Munculnya usaha baru berbasis isu &\\npotensi D...   \n",
       "\n",
       "                                                modul  \n",
       "0   Perubahan menuju sustainable mindset; 5 Prinsi...  \n",
       "1   Growth mindset; Design thinking; Lean Startup;...  \n",
       "2   Mengenal Sustainable Startup; SDGs 12 Responsi...  \n",
       "3   Sustainability Leadership; Coral Reef Ecology;...  \n",
       "4   Ecoturism Introduction; Sustainable Tourism Pr...  \n",
       "5   Pengenalan Kelor; Pemahaman Kelor Melalui sosi...  \n",
       "6   Forest Management and Conservation Program (FM...  \n",
       "7   Eco Literasi (Perubahan Mindset; 5 Prinsip Eko...  \n",
       "8   Analisis Masalah Sistem pertanian dan pengenal...  \n",
       "9   Dasar - dasar solar PV\\r\\nPemahaman dasar rang...  \n",
       "10  Sustainable Startup (Mengenal Sustainable Star...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04908784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "judul:\n",
      "Indonesia Sustainability Coral Reef University Network (ISCORE)\n",
      "\n",
      "\n",
      "deskripsi:\n",
      "Terumbu karang menutupi kurang dari 1% wilayah lautan, tetapi mereka secara langsung mendukung jutaan orang dengan\n",
      "menyediakan makanan, pekerjaan, dan sumber daya lainnya. Bahkan lebih banyak orang yang mendapat manfaat dari\n",
      "terumbu karang secara tidak langsung; ekosistem ini membantu memberi makan 1 miliar orang di Asia saja.\n",
      "Populasi manusia hampir 7 miliar orang, dan kemungkinan akan tumbuh menjadi 9 miliar pada tahun 2040. Kita\n",
      "membutuhkan terumbu karang (dan ekosistem lainnya) untuk memasok lebih banyak sumber daya untuk mendukung\n",
      "jumlah kita yang terus bertambah, tetapi mereka semakin terancam dengan kehancuran .\n",
      "\n",
      "\n",
      "dampak:\n",
      "pelindungan habibat; mengurangi polusi; mengurangi dampak erosi; promosi pariwisata; meningkatkan komunitas lokal; pemeliharaan agen perubahan berkelanjutan dan perlindungan terumbu karang\n",
      "\n",
      "\n",
      "modul:\n",
      "Sustainability Leadership; Coral Reef Ecology; Human threats & Challenges; Integrating Sustainability in Coral Reef; Improving reef management by sustainable financing for Communities benefit\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# periksa sampel teks\n",
    "def sample_text(df, idx):\n",
    "    for col in df.columns[1:]:\n",
    "        print(f'{col}:')\n",
    "        print(df[col].iloc[idx])\n",
    "        print('\\n')\n",
    "        \n",
    "sample_text(course, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1c62862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   courseID   11 non-null     int64 \n",
      " 1   judul      11 non-null     object\n",
      " 2   deskripsi  11 non-null     object\n",
      " 3   dampak     11 non-null     object\n",
      " 4   modul      11 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 568.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "course.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd075d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desa</th>\n",
       "      <th>problem</th>\n",
       "      <th>lokasi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>desa pinogu</td>\n",
       "      <td>Budidaya dan pengolahan kopi</td>\n",
       "      <td>gorontalo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>desa pinogu</td>\n",
       "      <td>Pengolahan produk dari sapi</td>\n",
       "      <td>gorontalo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desa pinogu</td>\n",
       "      <td>Akses jalan yang buruk</td>\n",
       "      <td>gorontalo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>desa pinogu</td>\n",
       "      <td>Listrik yang kurang menyeluruh</td>\n",
       "      <td>gorontalo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>desa pinogu</td>\n",
       "      <td>Jaringan internet yang kurang lancar</td>\n",
       "      <td>gorontalo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>desa aimoli</td>\n",
       "      <td>Wisata kuliner yang terbatas</td>\n",
       "      <td>alor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>desa aimoli</td>\n",
       "      <td>Akses informasi wisata yang masih terbatas</td>\n",
       "      <td>alor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>desa aimoli</td>\n",
       "      <td>Faslitas penunjang yang masih terbatas</td>\n",
       "      <td>alor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>desa aimoli</td>\n",
       "      <td>Belum ada inovasi pengelolaan SDA, seperti mak...</td>\n",
       "      <td>alor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>desa aimoli</td>\n",
       "      <td>Sumber daya manusia yang rendah untuk mengemba...</td>\n",
       "      <td>alor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           desa                                            problem     lokasi\n",
       "0   desa pinogu                       Budidaya dan pengolahan kopi  gorontalo\n",
       "1   desa pinogu                        Pengolahan produk dari sapi  gorontalo\n",
       "2   desa pinogu                             Akses jalan yang buruk  gorontalo\n",
       "3   desa pinogu                     Listrik yang kurang menyeluruh  gorontalo\n",
       "4   desa pinogu               Jaringan internet yang kurang lancar  gorontalo\n",
       "..          ...                                                ...        ...\n",
       "78  desa aimoli                       Wisata kuliner yang terbatas       alor\n",
       "79  desa aimoli         Akses informasi wisata yang masih terbatas       alor\n",
       "80  desa aimoli             Faslitas penunjang yang masih terbatas       alor\n",
       "81  desa aimoli  Belum ada inovasi pengelolaan SDA, seperti mak...       alor\n",
       "82  desa aimoli  Sumber daya manusia yang rendah untuk mengemba...       alor\n",
       "\n",
       "[83 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc4184ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83 entries, 0 to 82\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   desa     83 non-null     object\n",
      " 1   problem  83 non-null     object\n",
      " 2   lokasi   83 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "problem.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bef98cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # agregat tiap masalah pada 1 desa menjadi list dalam 1 baris\n",
    "# problem_agg = (problem.groupby(['desa','lokasi'])\n",
    "#           .agg({'problem': lambda x: \", \".join(x)})\n",
    "#           .rename({'Case' : 'Avg_Cases','Delivery' : 'Avg_Delivery'},axis=1)\n",
    "#           .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3d6396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f302eae",
   "metadata": {},
   "source": [
    "## Stemming & Remove Stopwords\n",
    "\n",
    "Stemming = mengubah kata imbuhan menjadi kata dasar </br>\n",
    "Stopwords = Stop list ini berisi daftar kata umum yang mempunyai fungsi tapi tidak mempunyai art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c2b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_clean = course.copy()\n",
    "prob_clean = problem.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce560a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "705"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# variable to clear symbols\n",
    "clean_spcl = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "clean_symbol = re.compile('[^0-9a-z #+_]')\n",
    "\n",
    "# stopword\n",
    "f = open(\"tala_stopword.txt\", \"r\")\n",
    "stopword_list = []\n",
    "for line in f:\n",
    "    stripped_line = line.strip()\n",
    "    line_list = stripped_line.split()\n",
    "    stopword_list.append(line_list[0])\n",
    "f.close()\n",
    "\n",
    "len(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "265a97e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = stemmer.stem(text)\n",
    "    text = text.lower() # lowercase text\n",
    "    text = clean_spcl.sub(' ', text)\n",
    "    text = clean_symbol.sub('', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in stopword_list) # hapus stopword dari kolom deskripsi\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0309fa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_clean['deskripsi'] = course_clean['deskripsi'].apply(clean_text)\n",
    "course_clean['dampak'] = course_clean['dampak'].apply(clean_text)\n",
    "course_clean['modul'] = course_clean['modul'].apply(clean_text)\n",
    "prob_clean['problem'] = problem['problem'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85c9be78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "judul:\n",
      "Indonesia Sustainability Coral Reef University Network (ISCORE)\n",
      "\n",
      "\n",
      "deskripsi:\n",
      "terumbu karang tutup 1 wilayah laut langsung dukung juta orang sedia makan kerja sumber daya bahkan banyak orang manfaat terumbu karang langsung ekosistem bantu makan 1 miliar orang asia populasi manusia 7 miliar orang akan tumbuh 9 miliar 2040 butuh terumbu karang ekosistem pasok banyak sumber daya dukung ancam hancur\n",
      "\n",
      "\n",
      "dampak:\n",
      "lindung habibat polusi dampak erosi promosi pariwisata tingkat komunitas lokal pelihara agen ubah lindung terumbu karang\n",
      "\n",
      "\n",
      "modul:\n",
      "sustainability leadership coral reef ecology human threats challenges integrating sustainability in coral reef improving reef management by sustainable financing for communities benefit\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_text(course_clean, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "221df79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'budidaya olah kopi'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_clean['problem'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b689b670",
   "metadata": {},
   "source": [
    "## TF-IDF dan Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd1d7a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengubah kalimat menjadi angka berupa matriks\n",
    "def conv_to_tf_idf(df, set_to_idx, col_transform):\n",
    "    df.set_index(set_to_idx, inplace=True)\n",
    "    tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0)\n",
    "    tfidf_matrix = tf.fit_transform(col_transform)\n",
    "    cos_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "289b805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_course = conv_to_tf_idf(course_clean, 'judul', course_clean['deskripsi'])\n",
    "cos_sim_prob = conv_to_tf_idf(prob_clean, 'desa', prob_clean['problem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1f3a373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.0410249 ,\n",
       "        0.0410249 ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.03207991,\n",
       "        0.00711276, 0.00759292, 0.00450875, 0.00767963, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.03207991, 1.        ,\n",
       "        0.01174512, 0.00258723, 0.02030233, 0.00464064, 0.02612287,\n",
       "        0.02612287],\n",
       "       [0.        , 0.        , 0.        , 0.00711276, 0.01174512,\n",
       "        1.        , 0.0476343 , 0.02042758, 0.01345511, 0.02190086,\n",
       "        0.02190086],\n",
       "       [0.        , 0.        , 0.        , 0.00759292, 0.00258723,\n",
       "        0.0476343 , 1.        , 0.01902052, 0.02499943, 0.02139556,\n",
       "        0.02139556],\n",
       "       [0.        , 0.        , 0.        , 0.00450875, 0.02030233,\n",
       "        0.02042758, 0.01902052, 1.        , 0.        , 0.08079424,\n",
       "        0.08079424],\n",
       "       [0.        , 0.        , 0.        , 0.00767963, 0.00464064,\n",
       "        0.01345511, 0.02499943, 0.        , 1.        , 0.01918832,\n",
       "        0.01918832],\n",
       "       [0.        , 0.        , 0.0410249 , 0.        , 0.02612287,\n",
       "        0.02190086, 0.02139556, 0.08079424, 0.01918832, 1.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.        , 0.0410249 , 0.        , 0.02612287,\n",
       "        0.02190086, 0.02139556, 0.08079424, 0.01918832, 1.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa0ecb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.09858882, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.09858882, 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.02368081],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.02368081,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0231570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                Fundamental Course (1)\n",
       "1                                Fundamental Course (2)\n",
       "2                                Fundamental Course (3)\n",
       "3     Indonesia Sustainability Coral Reef University...\n",
       "4                                            Ecotourism\n",
       "5                                       Moringa Academy\n",
       "6     Indonesia Sustainable Social Forestry Educatio...\n",
       "7                                      Waste Management\n",
       "8                                    Integrated Farming\n",
       "9                                         Solar Academy\n",
       "10                                      Program Startup\n",
       "Name: judul, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = pd.Series(course_clean.index)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62b983ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendations(name, cos_sim = cos_sim_prob):\n",
    "    \n",
    "    recommendation_desa = []\n",
    "    \n",
    "    # Mengambil nama hotel berdasarkan variabel indicies\n",
    "    idx = indices[indices == name].index[0]\n",
    "\n",
    "    # Membuat series berdasarkan skor kesamaan\n",
    "    score_series = pd.Series(cos_sim_prob[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # mengambil index dan dibuat 10 baris rekomendasi terbaik\n",
    "    top_10_indexes = list(score_series.iloc[1:len(score_series)].index)\n",
    "    \n",
    "    for i in top_10_indexes:\n",
    "        recommendation_desa.append(list(prob_clean.index)[i])\n",
    "        \n",
    "    return recommendation_desa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd13396a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa pinogu',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa saleman',\n",
       " 'desa saleman',\n",
       " 'desa lewalu',\n",
       " 'desa saleman',\n",
       " 'desa pinogu',\n",
       " 'desa saleman',\n",
       " 'desa saleman',\n",
       " 'desa saleman',\n",
       " 'desa saleman',\n",
       " 'desa saleman',\n",
       " 'desa saleman',\n",
       " 'desa saleman',\n",
       " 'desa saleman',\n",
       " 'desa saleman',\n",
       " 'desa saleman',\n",
       " 'desa saleman',\n",
       " 'desa saleman',\n",
       " 'desa lewalu',\n",
       " 'desa lewalu',\n",
       " 'desa saleman',\n",
       " 'desa aimoli',\n",
       " 'desa aimoli',\n",
       " 'desa aimoli',\n",
       " 'desa aimoli',\n",
       " 'desa aimoli',\n",
       " 'desa lewalu',\n",
       " 'desa lewalu',\n",
       " 'desa lewalu',\n",
       " 'desa lewalu',\n",
       " 'desa lewalu',\n",
       " 'desa lewalu',\n",
       " 'desa lewalu',\n",
       " 'desa lewalu',\n",
       " 'desa lewalu',\n",
       " 'desa lewalu',\n",
       " 'desa lewalu',\n",
       " 'desa lewalu',\n",
       " 'desa saleman',\n",
       " 'desa dataran hijau',\n",
       " 'desa saleman',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa pinogu',\n",
       " 'desa dataran hijau',\n",
       " 'desa saleman',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa pinogu',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa dataran hijau',\n",
       " 'desa aimoli']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations('Moringa Academy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b135cfa3-b6d5-4c6b-8c02-b11387077e3a",
   "metadata": {},
   "source": [
    "# Aggregate tiap problem di Desa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1b56b28-5007-452a-95a5-09ce2ee2d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregat tiap masalah pada 1 desa menjadi list dalam 1 baris\n",
    "problem_agg = (problem.groupby(['desa','lokasi'])\n",
    "          .agg({'problem': lambda x: \", \".join(x)})\n",
    "          .rename({'Case' : 'Avg_Cases','Delivery' : 'Avg_Delivery'},axis=1)\n",
    "          .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bc7b3a4-d171-4a30-9bb4-d7dc2d88d208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desa</th>\n",
       "      <th>lokasi</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>desa aimoli</td>\n",
       "      <td>alor</td>\n",
       "      <td>Fasilitas penunjang wisata yang masih minim, W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>desa dataran hijau</td>\n",
       "      <td>gorontalo</td>\n",
       "      <td>Akses yang sulit, Infrastruktur, kendala listr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desa lewalu</td>\n",
       "      <td>alor</td>\n",
       "      <td>Sulit mencari souvenir atau oleh-oleh, Sampah,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>desa pinogu</td>\n",
       "      <td>gorontalo</td>\n",
       "      <td>Budidaya dan pengolahan kopi, Pengolahan produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>desa saleman</td>\n",
       "      <td>maluku</td>\n",
       "      <td>Budaya masyarakat buang sampah ke laut, Etika ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 desa     lokasi   \n",
       "0         desa aimoli       alor  \\\n",
       "1  desa dataran hijau  gorontalo   \n",
       "2         desa lewalu       alor   \n",
       "3         desa pinogu  gorontalo   \n",
       "4        desa saleman     maluku   \n",
       "\n",
       "                                             problem  \n",
       "0  Fasilitas penunjang wisata yang masih minim, W...  \n",
       "1  Akses yang sulit, Infrastruktur, kendala listr...  \n",
       "2  Sulit mencari souvenir atau oleh-oleh, Sampah,...  \n",
       "3  Budidaya dan pengolahan kopi, Pengolahan produ...  \n",
       "4  Budaya masyarakat buang sampah ke laut, Etika ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d6786c4-7ae3-4ca3-94bd-f14e19b3180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_clean = course.copy()\n",
    "prob_clean = problem.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8d9602b-b6ee-4ce7-8d24-d0b12dd8477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_clean['deskripsi'] = course_clean['deskripsi'].apply(clean_text)\n",
    "course_clean['dampak'] = course_clean['dampak'].apply(clean_text)\n",
    "course_clean['modul'] = course_clean['modul'].apply(clean_text)\n",
    "prob_clean['problem'] = problem_agg['problem'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c3c32a1-cffe-4607-9d84-06d6ecd1b337",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cos_sim_course \u001b[38;5;241m=\u001b[39m conv_to_tf_idf(course_clean, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjudul\u001b[39m\u001b[38;5;124m'\u001b[39m, course_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeskripsi\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m cos_sim_prob \u001b[38;5;241m=\u001b[39m \u001b[43mconv_to_tf_idf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdesa\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprob_clean\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproblem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m, in \u001b[0;36mconv_to_tf_idf\u001b[0;34m(df, set_to_idx, col_transform)\u001b[0m\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mset_index(set_to_idx, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m tf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(analyzer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m, ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m), min_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m cos_sim \u001b[38;5;241m=\u001b[39m cosine_similarity(tfidf_matrix, tfidf_matrix)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cos_sim\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2133\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m   2127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2128\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2129\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2130\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2131\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2132\u001b[0m )\n\u001b[0;32m-> 2133\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2135\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2136\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1380\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1381\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m             )\n\u001b[1;32m   1386\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1391\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1275\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1274\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1276\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:106\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m\"\"\"Chain together an optional series of text processing steps to go from\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03ma single document to ngrams, with or without tokenizing or preprocessing.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    A sequence of tokens, possibly with pairs, triples, etc.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m     doc \u001b[38;5;241m=\u001b[39m analyzer(doc)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:239\u001b[0m, in \u001b[0;36m_VectorizerMixin.decode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    236\u001b[0m     doc \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_error)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan:\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.nan is an invalid document, expected byte or unicode string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    241\u001b[0m     )\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "cos_sim_course = conv_to_tf_idf(course_clean, 'judul', course_clean['deskripsi'])\n",
    "cos_sim_prob = conv_to_tf_idf(prob_clean, 'desa', prob_clean['problem'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
